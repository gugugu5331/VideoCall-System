# Edge-LLM-Infra æ¨¡å‹éªŒè¯æŠ¥å‘Š

**æ—¥æœŸ**: 2025-10-08  
**ç›®æ ‡**: éªŒè¯ Edge-LLM-Infra æ˜¯å¦çœŸæ­£åŠ è½½å¹¶ä½¿ç”¨äº† AI æ¨¡å‹

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

**ç»“è®º**: âŒ **Edge-LLM-Infra ä½¿ç”¨çš„æ˜¯è™šæ‹Ÿæ¨¡å‹å’Œæ¨¡æ‹Ÿæ•°æ®ï¼Œä¸æ˜¯çœŸå®çš„ AI æ¨ç†**

**å…³é”®å‘ç°**:
1. âŒ æ¨¡å‹æ–‡ä»¶æ˜¯è™šæ‹Ÿçš„ï¼ˆä»… 160-198 bytesï¼‰
2. âŒ ASR è¿”å›ç¡¬ç¼–ç çš„å›ºå®šæ–‡æœ¬
3. âš ï¸ Emotion Detection å’Œ Synthesis Detection ä½¿ç”¨æ¨¡å‹è¾“å‡ºï¼Œä½†æ¨¡å‹æ˜¯è™šæ‹Ÿçš„
4. âœ… ONNX Runtime æˆåŠŸåŠ è½½äº†è™šæ‹Ÿæ¨¡å‹

---

## ğŸ” è¯¦ç»†åˆ†æ

### 1. æ¨¡å‹æ–‡ä»¶éªŒè¯

**æ£€æŸ¥å‘½ä»¤**:
```bash
ls -lh /work/models/
```

**ç»“æœ**:
```
total 12K
-rw-r--r-- 1 root root 160 Oct  7 14:44 asr-model.onnx
-rw-r--r-- 1 root root 198 Oct  7 14:44 emotion-model.onnx
-rw-r--r-- 1 root root 176 Oct  7 14:44 synthesis-model.onnx
```

**åˆ†æ**:
- âŒ **æ–‡ä»¶å¤ªå°**ï¼šçœŸå®çš„ ONNX æ¨¡å‹é€šå¸¸æ˜¯å‡  MB åˆ°å‡ ç™¾ MB
- âŒ **è™šæ‹Ÿæ¨¡å‹**ï¼šè¿™äº›æ–‡ä»¶åªåŒ…å«åŸºæœ¬çš„æ¨¡å‹ç»“æ„ï¼ˆè¾“å…¥/è¾“å‡ºå®šä¹‰ï¼‰ï¼Œæ²¡æœ‰çœŸå®çš„æƒé‡æ•°æ®

**æ–‡ä»¶å†…å®¹**ï¼ˆasr-model.onnxï¼‰:
```
dummy_asr:ï¿½
-
audio_inputtranscription_output"Identity	asr_modelZ!
audio_input


d
Pb+
transcription_output


d
ï¿½B
```

**ç»“è®º**: è¿™äº›æ˜¯**è™šæ‹Ÿçš„ ONNX æ¨¡å‹**ï¼Œç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºï¼Œä¸åŒ…å«çœŸå®çš„ AI æƒé‡ã€‚

---

### 2. æºä»£ç åˆ†æ

#### ASR Taskï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰

**æ–‡ä»¶**: `node/llm/src/asr_task.cpp`  
**æ–¹æ³•**: `postprocess_output`ï¼ˆç¬¬ 216-239 è¡Œï¼‰

```cpp
std::string ASRTask::postprocess_output(const std::vector<float> &output) {
    // Simple postprocessing: find argmax and convert to text
    // In a real implementation, this would involve:
    // 1. CTC decoding or attention-based decoding
    // 2. Vocabulary mapping
    // 3. Language model integration
    
    if (output.empty()) {
        return "No transcription available";
    }
    
    // Find max probability
    auto max_it = std::max_element(output.begin(), output.end());
    int max_idx = std::distance(output.begin(), max_it);
    float confidence = *max_it;
    
    // Create JSON response
    nlohmann::json result;
    result["transcription"] = "Sample transcription text";  // âŒ ç¡¬ç¼–ç ï¼
    result["confidence"] = confidence;
    result["model"] = model_;
    
    return result.dump();
}
```

**é—®é¢˜**:
- âŒ **ç¬¬ 234 è¡Œ**ï¼šç¡¬ç¼–ç äº†å›ºå®šæ–‡æœ¬ `"Sample transcription text"`
- âŒ **ä¸ä½¿ç”¨æ¨¡å‹è¾“å‡º**ï¼šè™½ç„¶è®¡ç®—äº† `confidence`ï¼Œä½†è½¬å½•æ–‡æœ¬æ˜¯å›ºå®šçš„
- âŒ **æ³¨é‡Šè¯´æ˜**ï¼šä»£ç æ³¨é‡Šæ˜ç¡®è¯´æ˜è¿™æ˜¯ç®€åŒ–å®ç°ï¼ŒçœŸå®å®ç°éœ€è¦ CTC è§£ç ã€è¯æ±‡æ˜ å°„ç­‰

**ç»“è®º**: ASR è¿”å›çš„æ˜¯**ç¡¬ç¼–ç çš„å›ºå®šæ–‡æœ¬**ï¼Œä¸æ˜¯çœŸå®çš„è¯­éŸ³è¯†åˆ«ç»“æœã€‚

---

#### Emotion Detectionï¼ˆæƒ…æ„Ÿæ£€æµ‹ï¼‰

**æ–‡ä»¶**: `node/llm/src/emotion_task.cpp`  
**æ–¹æ³•**: `postprocess_output`ï¼ˆç¬¬ 216-260 è¡Œï¼‰

```cpp
std::string EmotionTask::postprocess_output(const std::vector<float> &output) {
    // Apply softmax and find the emotion with highest probability
    
    if (output.empty()) {
        return "No emotion detected";
    }
    
    // Apply softmax
    std::vector<float> probabilities;
    float sum = 0.0f;
    for (float val : output) {
        float exp_val = std::exp(val);
        probabilities.push_back(exp_val);
        sum += exp_val;
    }
    
    for (float& prob : probabilities) {
        prob /= sum;
    }
    
    // Find emotion with highest probability
    auto max_it = std::max_element(probabilities.begin(), probabilities.end());
    int max_idx = std::distance(probabilities.begin(), max_it);
    float confidence = *max_it;
    
    std::string detected_emotion = "unknown";
    if (max_idx < emotion_labels_.size()) {
        detected_emotion = emotion_labels_[max_idx];  // âœ… ä½¿ç”¨æ¨¡å‹è¾“å‡º
    }
    
    // Create JSON response
    nlohmann::json result;
    result["emotion"] = detected_emotion;
    result["confidence"] = confidence;
    result["model"] = model_;
    
    // Add all emotion probabilities
    nlohmann::json all_emotions;
    for (size_t i = 0; i < std::min(probabilities.size(), emotion_labels_.size()); i++) {
        all_emotions[emotion_labels_[i]] = probabilities[i];
    }
    result["all_emotions"] = all_emotions;
    
    return result.dump();
}
```

**åˆ†æ**:
- âœ… **ä½¿ç”¨æ¨¡å‹è¾“å‡º**ï¼šæ ¹æ®æ¨¡å‹è¾“å‡ºçš„æ¦‚ç‡é€‰æ‹©æƒ…æ„Ÿ
- âœ… **åº”ç”¨ Softmax**ï¼šæ­£ç¡®çš„åå¤„ç†é€»è¾‘
- âš ï¸ **ä½†æ¨¡å‹æ˜¯è™šæ‹Ÿçš„**ï¼šè™½ç„¶ä»£ç æ­£ç¡®ï¼Œä½†æ¨¡å‹æ²¡æœ‰çœŸå®æƒé‡

**ç»“è®º**: Emotion Detection çš„ä»£ç å®ç°æ­£ç¡®ï¼Œä½†ç”±äºæ¨¡å‹æ˜¯è™šæ‹Ÿçš„ï¼Œè¾“å‡ºä»ç„¶æ˜¯åŸºäºéšæœº/å›ºå®šæ•°æ®ã€‚

---

#### Synthesis Detectionï¼ˆæ·±åº¦ä¼ªé€ æ£€æµ‹ï¼‰

**æ–‡ä»¶**: `node/llm/src/synthesis_task.cpp`  
**æ–¹æ³•**: `postprocess_output`ï¼ˆç¬¬ 210-238 è¡Œï¼‰

```cpp
std::string SynthesisTask::postprocess_output(const std::vector<float> &output) {
    // Binary classification: real vs synthetic
    // Apply sigmoid to get probability
    
    if (output.empty()) {
        return "No detection result available";
    }
    
    // Get the first output value (assuming binary classification)
    float raw_score = output[0];
    
    // Apply sigmoid function
    float probability = 1.0f / (1.0f + std::exp(-raw_score));
    
    // Determine if synthetic (threshold at 0.5)
    bool is_synthetic = probability > 0.5f;
    float confidence = is_synthetic ? probability : (1.0f - probability);
    
    // Create JSON response
    nlohmann::json result;
    result["is_synthetic"] = is_synthetic;
    result["is_real"] = !is_synthetic;
    result["confidence"] = confidence;
    result["probability_synthetic"] = probability;
    result["probability_real"] = 1.0f - probability;
    result["model"] = model_;
    
    return result.dump();
}
```

**åˆ†æ**:
- âœ… **ä½¿ç”¨æ¨¡å‹è¾“å‡º**ï¼šæ ¹æ®æ¨¡å‹è¾“å‡ºçš„åˆ†æ•°åˆ¤æ–­æ˜¯å¦ä¸ºåˆæˆéŸ³é¢‘
- âœ… **åº”ç”¨ Sigmoid**ï¼šæ­£ç¡®çš„åå¤„ç†é€»è¾‘
- âš ï¸ **ä½†æ¨¡å‹æ˜¯è™šæ‹Ÿçš„**ï¼šè™½ç„¶ä»£ç æ­£ç¡®ï¼Œä½†æ¨¡å‹æ²¡æœ‰çœŸå®æƒé‡

**ç»“è®º**: Synthesis Detection çš„ä»£ç å®ç°æ­£ç¡®ï¼Œä½†ç”±äºæ¨¡å‹æ˜¯è™šæ‹Ÿçš„ï¼Œè¾“å‡ºä»ç„¶æ˜¯åŸºäºéšæœº/å›ºå®šæ•°æ®ã€‚

---

## ğŸ“Š æµ‹è¯•éªŒè¯

### æµ‹è¯• 1: å ä½ç¬¦æ•°æ® vs çœŸå®éŸ³é¢‘

| æµ‹è¯•é¡¹ | è¾“å…¥ | è¾“å‡º | ç»“è®º |
|--------|------|------|------|
| **ASRï¼ˆå ä½ç¬¦ï¼‰** | "sample audio data" (17 bytes) | "Sample transcription text" | âŒ å›ºå®šæ–‡æœ¬ |
| **ASRï¼ˆçœŸå®éŸ³é¢‘ï¼‰** | 115KB MP3 æ–‡ä»¶ | "Sample transcription text" | âŒ å›ºå®šæ–‡æœ¬ |

**ç»“è®º**: æ— è®ºè¾“å…¥ä»€ä¹ˆéŸ³é¢‘æ•°æ®ï¼ŒASR éƒ½è¿”å›ç›¸åŒçš„å›ºå®šæ–‡æœ¬ã€‚

---

### æµ‹è¯• 2: æ¨¡å‹åŠ è½½æ—¥å¿—

**Edge-LLM-Infra æ—¥å¿—**:
```
[ASRTask] load_model called
[ASRTask] Config parsed successfully, model=asr-model
[ASRTask] Initializing ONNX Runtime...
[ASRTask] ONNX Runtime initialized
Loading ASR model from: /work/models/asr-model.onnx
2025-10-08 02:24:41.047231519 [W:onnxruntime:, graph.cc:108 MergeShapeInfo] Error merging shape info for output. 'transcription_output' source:{1,100,80} target:{1,100,1000}. Falling back to lenient merge.
ASR model loaded successfully
```

**åˆ†æ**:
- âœ… ONNX Runtime æˆåŠŸåŠ è½½äº†æ¨¡å‹
- âš ï¸ æœ‰è­¦å‘Šï¼šè¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…ï¼ˆ`{1,100,80}` vs `{1,100,1000}`ï¼‰
- âš ï¸ è¿™è¯´æ˜æ¨¡å‹ç»“æ„æ˜¯è™šæ‹Ÿçš„ï¼Œä¸æ˜¯çœŸå®è®­ç»ƒçš„æ¨¡å‹

**ç»“è®º**: ONNX Runtime åŠ è½½äº†è™šæ‹Ÿæ¨¡å‹ï¼Œä½†æ¨¡å‹æ²¡æœ‰çœŸå®çš„æƒé‡æ•°æ®ã€‚

---

## ğŸ’¡ é—®é¢˜æ ¹æº

### ä¸ºä»€ä¹ˆä½¿ç”¨è™šæ‹Ÿæ¨¡å‹ï¼Ÿ

**å¯èƒ½åŸå› **:
1. **æ¼”ç¤º/æµ‹è¯•ç›®çš„**ï¼šEdge-LLM-Infra æ˜¯ä¸€ä¸ªæ¡†æ¶æ¼”ç¤ºï¼Œä¸åŒ…å«çœŸå®çš„ AI æ¨¡å‹
2. **æ¨¡å‹æ–‡ä»¶å¤ªå¤§**ï¼šçœŸå®çš„ AI æ¨¡å‹æ–‡ä»¶é€šå¸¸å¾ˆå¤§ï¼ˆå‡ ç™¾ MB åˆ°å‡  GBï¼‰ï¼Œä¸é€‚åˆåŒ…å«åœ¨ä»£ç ä»“åº“ä¸­
3. **è®¸å¯è¯é—®é¢˜**ï¼šçœŸå®çš„é¢„è®­ç»ƒæ¨¡å‹å¯èƒ½æœ‰è®¸å¯è¯é™åˆ¶
4. **å¼€å‘é˜¶æ®µ**ï¼šç³»ç»Ÿä»åœ¨å¼€å‘ä¸­ï¼Œä½¿ç”¨è™šæ‹Ÿæ¨¡å‹è¿›è¡ŒåŠŸèƒ½æµ‹è¯•

### è™šæ‹Ÿæ¨¡å‹çš„ç‰¹å¾

1. **æ–‡ä»¶å¾ˆå°**ï¼š160-198 bytesï¼ˆçœŸå®æ¨¡å‹é€šå¸¸æ˜¯ MB çº§åˆ«ï¼‰
2. **åªæœ‰ç»“æ„**ï¼šåŒ…å«è¾“å…¥/è¾“å‡ºå®šä¹‰ï¼Œä½†æ²¡æœ‰æƒé‡æ•°æ®
3. **Identity æ“ä½œ**ï¼šè™šæ‹Ÿæ¨¡å‹é€šå¸¸ä½¿ç”¨ Identity æ“ä½œï¼ˆç›´æ¥ä¼ é€’è¾“å…¥ï¼‰
4. **å›ºå®šè¾“å‡º**ï¼šç”±äºæ²¡æœ‰çœŸå®æƒé‡ï¼Œè¾“å‡ºæ˜¯éšæœºæˆ–å›ºå®šçš„

---

## ğŸ¯ ä¿®å¤å»ºè®®

### é€‰é¡¹ 1: ä½¿ç”¨çœŸå®çš„ AI æ¨¡å‹ï¼ˆæ¨èï¼‰

**æ­¥éª¤**:
1. **è·å–çœŸå®çš„ ONNX æ¨¡å‹**ï¼š
   - ASR: ä½¿ç”¨ Whisperã€DeepSpeech ç­‰æ¨¡å‹
   - Emotion Detection: ä½¿ç”¨æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹
   - Synthesis Detection: ä½¿ç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹

2. **è½¬æ¢ä¸º ONNX æ ¼å¼**ï¼š
   ```bash
   # ç¤ºä¾‹ï¼šå°† PyTorch æ¨¡å‹è½¬æ¢ä¸º ONNX
   python -m torch.onnx.export model.pth model.onnx
   ```

3. **æ›¿æ¢è™šæ‹Ÿæ¨¡å‹**ï¼š
   ```bash
   cp real-asr-model.onnx /work/models/asr-model.onnx
   cp real-emotion-model.onnx /work/models/emotion-model.onnx
   cp real-synthesis-model.onnx /work/models/synthesis-model.onnx
   ```

4. **é‡æ–°å¯åŠ¨ Edge-LLM-Infra**ï¼š
   ```bash
   pkill -9 llm
   cd /root/meeting-system-server/meeting-system/Edge-LLM-Infra-master/node/llm/build
   ./llm > llm.log 2>&1 &
   ```

---

### é€‰é¡¹ 2: ä¿®æ”¹ ASR ä»£ç ä½¿ç”¨æ¨¡å‹è¾“å‡º

**ç›®æ ‡**: å³ä½¿ä½¿ç”¨è™šæ‹Ÿæ¨¡å‹ï¼Œä¹Ÿè®© ASR è¿”å›ä¸åŒçš„ç»“æœ

**ä¿®æ”¹æ–‡ä»¶**: `node/llm/src/asr_task.cpp`

**ä¿®æ”¹å‰**ï¼ˆç¬¬ 234 è¡Œï¼‰:
```cpp
result["transcription"] = "Sample transcription text";  // å›ºå®šæ–‡æœ¬
```

**ä¿®æ”¹å**:
```cpp
// ä½¿ç”¨æ¨¡å‹è¾“å‡ºç”Ÿæˆä¸åŒçš„æ–‡æœ¬ï¼ˆè™½ç„¶ä»ç„¶æ˜¯æ¨¡æ‹Ÿçš„ï¼‰
std::string transcription = "Transcription_" + std::to_string(max_idx) + "_conf_" + std::to_string(confidence);
result["transcription"] = transcription;
```

**æ•ˆæœ**:
- ä¸åŒçš„éŸ³é¢‘è¾“å…¥ä¼šäº§ç”Ÿä¸åŒçš„ `max_idx` å’Œ `confidence`
- è¿”å›çš„æ–‡æœ¬ä¼šä¸åŒï¼ˆè™½ç„¶ä»ç„¶ä¸æ˜¯çœŸå®çš„è½¬å½•ï¼‰
- è‡³å°‘å¯ä»¥éªŒè¯ç³»ç»Ÿæ˜¯å¦çœŸæ­£å¤„ç†äº†éŸ³é¢‘æ•°æ®

---

### é€‰é¡¹ 3: ä¿æŒç°çŠ¶ï¼ˆä¸æ¨èï¼‰

**è¯´æ˜**: å¦‚æœåªæ˜¯ä¸ºäº†æ¼”ç¤ºç³»ç»Ÿæ¶æ„ï¼Œå¯ä»¥ä¿æŒä½¿ç”¨è™šæ‹Ÿæ¨¡å‹

**ä¼˜ç‚¹**:
- ä¸éœ€è¦å¤§æ–‡ä»¶
- ç³»ç»Ÿè¿è¡Œå¿«é€Ÿ
- é€‚åˆåŠŸèƒ½æµ‹è¯•

**ç¼ºç‚¹**:
- âŒ ä¸æ˜¯çœŸå®çš„ AI æ¨ç†
- âŒ æ— æ³•éªŒè¯éŸ³é¢‘å¤„ç†é€»è¾‘
- âŒ ç”¨æˆ·ä¼šè®¤ä¸ºç³»ç»Ÿæœ‰é—®é¢˜

---

## ğŸ“ˆ çœŸå®æ¨¡å‹ vs è™šæ‹Ÿæ¨¡å‹å¯¹æ¯”

| ç‰¹å¾ | è™šæ‹Ÿæ¨¡å‹ï¼ˆå½“å‰ï¼‰ | çœŸå®æ¨¡å‹ï¼ˆæ¨èï¼‰ |
|------|----------------|----------------|
| **æ–‡ä»¶å¤§å°** | 160-198 bytes | å‡ ç™¾ MB åˆ°å‡  GB |
| **æƒé‡æ•°æ®** | âŒ æ—  | âœ… æœ‰ |
| **æ¨ç†ç»“æœ** | âŒ å›ºå®š/éšæœº | âœ… çœŸå®çš„ AI æ¨ç† |
| **ASR è¾“å‡º** | "Sample transcription text" | çœŸå®çš„è¯­éŸ³è½¬å½• |
| **Emotion è¾“å‡º** | åŸºäºéšæœºæ•°æ® | çœŸå®çš„æƒ…æ„Ÿåˆ†æ |
| **Synthesis è¾“å‡º** | åŸºäºéšæœºæ•°æ® | çœŸå®çš„æ·±åº¦ä¼ªé€ æ£€æµ‹ |
| **åŠ è½½æ—¶é—´** | å¿«é€Ÿï¼ˆ<1sï¼‰ | è¾ƒæ…¢ï¼ˆå‡ ç§’åˆ°å‡ åç§’ï¼‰ |
| **å†…å­˜å ç”¨** | å¾ˆå° | è¾ƒå¤§ï¼ˆå‡ ç™¾ MB åˆ°å‡  GBï¼‰ |
| **é€‚ç”¨åœºæ™¯** | æ¼”ç¤ºã€æµ‹è¯• | ç”Ÿäº§ç¯å¢ƒ |

---

## ğŸ‰ ç»“è®º

### å½“å‰çŠ¶æ€
- âŒ **Edge-LLM-Infra ä½¿ç”¨è™šæ‹Ÿæ¨¡å‹**ï¼Œä¸æ˜¯çœŸå®çš„ AI æ¨ç†
- âŒ **ASR è¿”å›å›ºå®šæ–‡æœ¬**ï¼Œä¸å¤„ç†éŸ³é¢‘å†…å®¹
- âš ï¸ **Emotion å’Œ Synthesis Detection ä»£ç æ­£ç¡®**ï¼Œä½†æ¨¡å‹æ˜¯è™šæ‹Ÿçš„
- âœ… **ç³»ç»Ÿæ¶æ„æ­£ç¡®**ï¼Œæµå¼ä¼ è¾“ã€æ•°æ®æ ¼å¼éƒ½æ²¡é—®é¢˜

### å»ºè®®
1. **å¦‚æœéœ€è¦çœŸå®çš„ AI æ¨ç†**ï¼šæ›¿æ¢ä¸ºçœŸå®çš„ ONNX æ¨¡å‹
2. **å¦‚æœåªæ˜¯æ¼”ç¤ºç³»ç»Ÿ**ï¼šå¯ä»¥ä¿æŒç°çŠ¶ï¼Œä½†éœ€è¦å‘ç”¨æˆ·è¯´æ˜
3. **å¦‚æœéœ€è¦éªŒè¯æ•°æ®å¤„ç†**ï¼šä¿®æ”¹ ASR ä»£ç ä½¿ç”¨æ¨¡å‹è¾“å‡º

### ä¸‹ä¸€æ­¥
- å†³å®šæ˜¯å¦éœ€è¦çœŸå®çš„ AI æ¨¡å‹
- å¦‚æœéœ€è¦ï¼Œè·å–æˆ–è®­ç»ƒçœŸå®çš„ ONNX æ¨¡å‹
- å¦‚æœä¸éœ€è¦ï¼Œå‘ç”¨æˆ·è¯´æ˜å½“å‰æ˜¯æ¼”ç¤ºç‰ˆæœ¬

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2025-10-08 02:35:00  
**éªŒè¯çŠ¶æ€**: âœ… **å®Œæˆ - ç¡®è®¤ä½¿ç”¨è™šæ‹Ÿæ¨¡å‹**  
**å»ºè®®**: æ›¿æ¢ä¸ºçœŸå®çš„ ONNX æ¨¡å‹ä»¥è·å¾—çœŸå®çš„ AI æ¨ç†ç»“æœ

