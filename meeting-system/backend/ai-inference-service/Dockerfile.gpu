# Build stage (self-contained Go 1.24 install to avoid拉取失败)
FROM debian:bookworm AS builder

ARG GO_VERSION=1.24.11
ARG GOPROXY=https://proxy.golang.com.cn,direct
ENV GOPROXY=${GOPROXY}
ENV GOSUMDB=off
ENV GOTOOLCHAIN=local

RUN apt-get update \
    && apt-get install -y --no-install-recommends ca-certificates curl build-essential git \
    && rm -rf /var/lib/apt/lists/*

# Install Go manually
RUN curl -fsSL https://go.dev/dl/go${GO_VERSION}.linux-amd64.tar.gz -o /tmp/go.tgz \
    && tar -C /usr/local -xzf /tmp/go.tgz \
    && ln -s /usr/local/go/bin/go /usr/local/bin/go \
    && ln -s /usr/local/go/bin/gofmt /usr/local/bin/gofmt

WORKDIR /build

# Copy backend sources (includes shared and ai-inference-service)
COPY . .

WORKDIR /build/ai-inference-service

RUN go mod download

# Build static binary for Triton client usage.
RUN CGO_ENABLED=0 GOOS=linux go build -o ai-inference-service .

# Runtime stage
FROM nvidia/cuda:12.2.2-cudnn8-runtime-ubuntu22.04

ENV TZ=Asia/Shanghai

RUN apt-get update \
    && apt-get install -y --no-install-recommends ca-certificates tzdata curl \
    && rm -rf /var/lib/apt/lists/*

# Triton runs remotely; no local ONNX runtime libraries required.

WORKDIR /app

COPY --from=builder /build/ai-inference-service/ai-inference-service .
COPY --from=builder /build/ai-inference-service/config ./config

RUN useradd -m appuser \
    && mkdir -p /app/logs \
    && chown -R appuser:appuser /app

USER appuser

EXPOSE 8085
EXPOSE 9085

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8085/health || exit 1

CMD ["./ai-inference-service"]
