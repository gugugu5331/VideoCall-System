#!/usr/bin/env python3
"""
Whisper ASR æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼

ä½¿ç”¨ OpenAI Whisper æ¨¡å‹è¿›è¡Œè¯­éŸ³è¯†åˆ«
æ”¯æŒå¤šè¯­è¨€ï¼ˆåŒ…æ‹¬ä¸­æ–‡ï¼‰
"""

import torch
import onnx
import numpy as np
from pathlib import Path
import sys

def convert_whisper_to_onnx(model_size="base", output_dir="/work/models"):
    """
    å°† Whisper æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼

    Args:
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
        output_dir: è¾“å‡ºç›®å½•
    """
    try:
        import whisper
    except ImportError:
        print(f"âŒ é”™è¯¯: éœ€è¦å®‰è£… openai-whisper")
        print(f"   pip install openai-whisper")
        return False

    print(f"=" * 80)
    print(f"ğŸ¯ å¼€å§‹è½¬æ¢ Whisper {model_size} æ¨¡å‹åˆ° ONNX æ ¼å¼")
    print(f"=" * 80)
    print()

    # 1. ä¸‹è½½ Whisper æ¨¡å‹
    print(f"ğŸ“¥ ä¸‹è½½ Whisper {model_size} æ¨¡å‹...")
    try:
        model = whisper.load_model(model_size)
        print(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        return False
    
    print()
    
    # 2. å‡†å¤‡å¯¼å‡º
    print(f"ğŸ”§ å‡†å¤‡å¯¼å‡ºç¼–ç å™¨...")
    
    # Whisper æ¨¡å‹åŒ…å«ç¼–ç å™¨å’Œè§£ç å™¨
    # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªå¯¼å‡ºç¼–ç å™¨éƒ¨åˆ†
    # ç¼–ç å™¨å°†éŸ³é¢‘ç‰¹å¾è½¬æ¢ä¸ºéšè—çŠ¶æ€
    encoder = model.encoder
    encoder.eval()
    
    # 3. åˆ›å»ºç¤ºä¾‹è¾“å…¥
    # Whisper æœŸæœ›çš„è¾“å…¥æ˜¯ mel-spectrogram
    # å½¢çŠ¶: (batch_size, n_mels, n_frames)
    # n_mels = 80 (å›ºå®š)
    # n_frames = 3000 (å¯¹åº” 30 ç§’éŸ³é¢‘)
    batch_size = 1
    n_mels = 80
    n_frames = 3000
    
    print(f"ğŸ“Š åˆ›å»ºç¤ºä¾‹è¾“å…¥: shape=({batch_size}, {n_mels}, {n_frames})")
    dummy_input = torch.randn(batch_size, n_mels, n_frames)
    
    # 4. å¯¼å‡ºä¸º ONNX
    output_path = Path(output_dir) / "asr-model.onnx"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ å¯¼å‡º ONNX æ¨¡å‹åˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            encoder,
            dummy_input,
            str(output_path),
            export_params=True,
            opset_version=14,
            do_constant_folding=True,
            input_names=['audio_input'],
            output_names=['transcription_output'],
            dynamic_axes={
                'audio_input': {0: 'batch_size', 2: 'n_frames'},
                'transcription_output': {0: 'batch_size', 1: 'sequence_length'}
            }
        )
        print(f"âœ… ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ONNX å¯¼å‡ºå¤±è´¥: {e}")
        return False
    
    print()
    
    # 5. éªŒè¯ ONNX æ¨¡å‹
    print(f"ğŸ” éªŒè¯ ONNX æ¨¡å‹...")
    try:
        onnx_model = onnx.load(str(output_path))
        onnx.checker.check_model(onnx_model)
        print(f"âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ ONNX æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False
    
    print()
    
    # 6. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
    print(f"   è¾“å…¥: audio_input (mel-spectrogram)")
    print(f"   è¾“å‡º: transcription_output (hidden states)")
    print()
    
    # 7. æµ‹è¯•æ¨ç†
    print(f"ğŸ§ª æµ‹è¯• ONNX æ¨ç†...")
    try:
        import onnxruntime as ort
        
        session = ort.InferenceSession(str(output_path))
        
        # å‡†å¤‡è¾“å…¥
        input_data = np.random.randn(1, 80, 3000).astype(np.float32)
        
        # è¿è¡Œæ¨ç†
        outputs = session.run(None, {'audio_input': input_data})
        
        print(f"âœ… ONNX æ¨ç†æˆåŠŸ")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    except Exception as e:
        print(f"âŒ ONNX æ¨ç†å¤±è´¥: {e}")
        return False
    
    print()
    print(f"=" * 80)
    print(f"ğŸ‰ Whisper æ¨¡å‹è½¬æ¢å®Œæˆï¼")
    print(f"=" * 80)
    print()
    print(f"ğŸ“ æ³¨æ„äº‹é¡¹:")
    print(f"   1. æ­¤æ¨¡å‹åªåŒ…å«ç¼–ç å™¨éƒ¨åˆ†")
    print(f"   2. éœ€è¦åœ¨ C++ ä»£ç ä¸­å®ç°è§£ç é€»è¾‘")
    print(f"   3. æˆ–è€…ä½¿ç”¨ç®€åŒ–çš„ CTC è§£ç ")
    print()
    
    return True


def create_simple_asr_model(output_dir="/work/models"):
    """
    åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„ ASR æ¨¡å‹ç”¨äºæ¼”ç¤º
    
    è¿™ä¸ªæ¨¡å‹ä¼šï¼š
    1. æ¥æ”¶éŸ³é¢‘ç‰¹å¾
    2. é€šè¿‡ç®€å•çš„ç¥ç»ç½‘ç»œ
    3. è¾“å‡ºå­—ç¬¦æ¦‚ç‡
    """
    print(f"=" * 80)
    print(f"ğŸ¯ åˆ›å»ºç®€åŒ–çš„ ASR æ¼”ç¤ºæ¨¡å‹")
    print(f"=" * 80)
    print()
    
    class SimpleASR(torch.nn.Module):
        def __init__(self):
            super().__init__()
            # ç®€å•çš„ LSTM + çº¿æ€§å±‚
            self.lstm = torch.nn.LSTM(
                input_size=80,  # mel-spectrogram features
                hidden_size=256,
                num_layers=2,
                batch_first=True,
                bidirectional=True
            )
            self.fc = torch.nn.Linear(512, 100)  # 100 ä¸ªå­—ç¬¦ç±»åˆ«
        
        def forward(self, x):
            # x: (batch, n_mels, n_frames)
            x = x.transpose(1, 2)  # (batch, n_frames, n_mels)
            lstm_out, _ = self.lstm(x)  # (batch, n_frames, 512)
            output = self.fc(lstm_out)  # (batch, n_frames, 100)
            return output
    
    print(f"ğŸ”§ åˆ›å»ºæ¨¡å‹...")
    model = SimpleASR()
    model.eval()
    
    # åˆ›å»ºç¤ºä¾‹è¾“å…¥
    dummy_input = torch.randn(1, 80, 100)  # (batch, n_mels, n_frames)
    
    # å¯¼å‡ºä¸º ONNX
    output_path = Path(output_dir) / "asr-model.onnx"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ å¯¼å‡º ONNX æ¨¡å‹åˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            model,
            dummy_input,
            str(output_path),
            export_params=True,
            opset_version=14,
            do_constant_folding=True,
            input_names=['audio_input'],
            output_names=['transcription_output'],
            dynamic_axes={
                'audio_input': {0: 'batch_size', 2: 'n_frames'},
                'transcription_output': {0: 'batch_size', 1: 'n_frames'}
            }
        )
        print(f"âœ… ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ONNX å¯¼å‡ºå¤±è´¥: {e}")
        return False
    
    print()
    
    # éªŒè¯æ¨¡å‹
    print(f"ğŸ” éªŒè¯ ONNX æ¨¡å‹...")
    try:
        onnx_model = onnx.load(str(output_path))
        onnx.checker.check_model(onnx_model)
        print(f"âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ ONNX æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False
    
    print()
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
    print(f"   è¾“å…¥å½¢çŠ¶: (batch, 80, n_frames)")
    print(f"   è¾“å‡ºå½¢çŠ¶: (batch, n_frames, 100)")
    print()
    
    # æµ‹è¯•æ¨ç†
    print(f"ğŸ§ª æµ‹è¯• ONNX æ¨ç†...")
    try:
        import onnxruntime as ort
        
        session = ort.InferenceSession(str(output_path))
        input_data = np.random.randn(1, 80, 100).astype(np.float32)
        outputs = session.run(None, {'audio_input': input_data})
        
        print(f"âœ… ONNX æ¨ç†æˆåŠŸ")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    except Exception as e:
        print(f"âŒ ONNX æ¨ç†å¤±è´¥: {e}")
        return False
    
    print()
    print(f"=" * 80)
    print(f"ğŸ‰ ç®€åŒ– ASR æ¨¡å‹åˆ›å»ºå®Œæˆï¼")
    print(f"=" * 80)
    
    return True


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è½¬æ¢ Whisper æ¨¡å‹åˆ° ONNX æ ¼å¼")
    parser.add_argument(
        "--model-size",
        type=str,
        default="base",
        choices=["tiny", "base", "small", "medium", "large"],
        help="Whisper æ¨¡å‹å¤§å°"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="/work/models",
        help="è¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--simple",
        action="store_true",
        help="åˆ›å»ºç®€åŒ–çš„æ¼”ç¤ºæ¨¡å‹ï¼ˆä¸ä¸‹è½½ Whisperï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.simple:
        success = create_simple_asr_model(args.output_dir)
    else:
        success = convert_whisper_to_onnx(args.model_size, args.output_dir)
    
    sys.exit(0 if success else 1)

