#!/usr/bin/env python3
"""
Synthesis Detection æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼

ç”¨äºæ£€æµ‹éŸ³é¢‘æ˜¯å¦ä¸º AI ç”Ÿæˆï¼ˆæ·±åº¦ä¼ªé€ æ£€æµ‹ï¼‰
è¾“å‡º: çœŸå®/åˆæˆçš„æ¦‚ç‡
"""

import torch
import torch.nn as nn
import onnx
import numpy as np
from pathlib import Path
import sys


class SimpleSynthesisDetector(nn.Module):
    """
    ç®€åŒ–çš„æ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹
    
    æ¶æ„:
    - è¾“å…¥: éŸ³é¢‘ç‰¹å¾ (mel-spectrogram)
    - CNN å±‚æå–å±€éƒ¨ç‰¹å¾
    - LSTM å±‚æå–æ—¶åºç‰¹å¾
    - å…¨è¿æ¥å±‚äºŒåˆ†ç±»
    - è¾“å‡º: åˆæˆæ¦‚ç‡
    """
    
    def __init__(self, n_mels=80, hidden_size=128):
        super().__init__()
        
        # CNN å±‚
        self.conv1 = nn.Conv1d(n_mels, 128, kernel_size=3, padding=1)
        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)
        self.pool = nn.MaxPool1d(2)
        self.dropout1 = nn.Dropout(0.3)
        
        # LSTM å±‚
        self.lstm = nn.LSTM(
            input_size=256,
            hidden_size=hidden_size,
            num_layers=2,
            batch_first=True,
            bidirectional=True,
            dropout=0.3
        )
        
        # æ³¨æ„åŠ›å±‚
        self.attention = nn.Linear(hidden_size * 2, 1)
        
        # åˆ†ç±»å±‚
        self.fc1 = nn.Linear(hidden_size * 2, 64)
        self.dropout2 = nn.Dropout(0.3)
        self.fc2 = nn.Linear(64, 1)  # äºŒåˆ†ç±»ï¼šçœŸå® vs åˆæˆ
    
    def forward(self, x):
        # x: (batch, n_mels, n_frames)
        
        # CNN
        x = torch.relu(self.conv1(x))
        x = self.pool(x)
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.dropout1(x)
        
        # è½¬æ¢ä¸º LSTM è¾“å…¥æ ¼å¼
        x = x.transpose(1, 2)  # (batch, n_frames, 256)
        
        # LSTM
        lstm_out, _ = self.lstm(x)  # (batch, n_frames, hidden_size*2)
        
        # Attention pooling
        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)
        attended = torch.sum(lstm_out * attention_weights, dim=1)
        
        # Classification
        x = torch.relu(self.fc1(attended))
        x = self.dropout2(x)
        output = self.fc2(x)  # (batch, 1)
        
        return output


def create_synthesis_model(output_dir="/work/models"):
    """
    åˆ›å»ºæ·±åº¦ä¼ªé€ æ£€æµ‹æ¨¡å‹å¹¶è½¬æ¢ä¸º ONNX æ ¼å¼
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"=" * 80)
    print(f"ğŸ¯ åˆ›å»º Synthesis Detection æ¨¡å‹")
    print(f"=" * 80)
    print()
    
    print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
    print(f"   è¾“å…¥: mel-spectrogram (80 x n_frames)")
    print(f"   è¾“å‡º: åˆæˆæ¦‚ç‡ (0-1)")
    print(f"   ä»»åŠ¡: äºŒåˆ†ç±»ï¼ˆçœŸå® vs åˆæˆï¼‰")
    print()
    
    # 1. åˆ›å»ºæ¨¡å‹
    print(f"ğŸ”§ åˆ›å»ºæ¨¡å‹...")
    model = SimpleSynthesisDetector(n_mels=80, hidden_size=128)
    model.eval()
    
    # åˆå§‹åŒ–æƒé‡
    print(f"âš™ï¸ åˆå§‹åŒ–æ¨¡å‹æƒé‡...")
    for name, param in model.named_parameters():
        if 'weight' in name:
            if 'conv' in name or 'fc' in name:
                nn.init.xavier_uniform_(param)
            else:
                nn.init.orthogonal_(param)
        elif 'bias' in name:
            nn.init.zeros_(param)
    
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    print()
    
    # 2. åˆ›å»ºç¤ºä¾‹è¾“å…¥
    batch_size = 1
    n_mels = 80
    n_frames = 100
    
    print(f"ğŸ“Š åˆ›å»ºç¤ºä¾‹è¾“å…¥: shape=({batch_size}, {n_mels}, {n_frames})")
    dummy_input = torch.randn(batch_size, n_mels, n_frames)
    
    # 3. å¯¼å‡ºä¸º ONNX
    output_path = Path(output_dir) / "synthesis-model.onnx"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ’¾ å¯¼å‡º ONNX æ¨¡å‹åˆ°: {output_path}")
    
    try:
        torch.onnx.export(
            model,
            dummy_input,
            str(output_path),
            export_params=True,
            opset_version=14,
            do_constant_folding=True,
            input_names=['audio_input'],
            output_names=['synthesis_output'],
            dynamic_axes={
                'audio_input': {0: 'batch_size', 2: 'n_frames'},
                'synthesis_output': {0: 'batch_size'}
            }
        )
        print(f"âœ… ONNX æ¨¡å‹å¯¼å‡ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ONNX å¯¼å‡ºå¤±è´¥: {e}")
        return False
    
    print()
    
    # 4. éªŒè¯ ONNX æ¨¡å‹
    print(f"ğŸ” éªŒè¯ ONNX æ¨¡å‹...")
    try:
        onnx_model = onnx.load(str(output_path))
        onnx.checker.check_model(onnx_model)
        print(f"âœ… ONNX æ¨¡å‹éªŒè¯é€šè¿‡")
    except Exception as e:
        print(f"âŒ ONNX æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
        return False
    
    print()
    
    # 5. æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    print(f"   æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024 / 1024:.2f} MB")
    print(f"   è¾“å…¥å½¢çŠ¶: (batch, 80, n_frames)")
    print(f"   è¾“å‡ºå½¢çŠ¶: (batch, 1)")
    print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print()
    
    # 6. æµ‹è¯•æ¨ç†
    print(f"ğŸ§ª æµ‹è¯• ONNX æ¨ç†...")
    try:
        import onnxruntime as ort
        
        session = ort.InferenceSession(str(output_path))
        
        # å‡†å¤‡è¾“å…¥
        input_data = np.random.randn(1, 80, 100).astype(np.float32)
        
        # è¿è¡Œæ¨ç†
        outputs = session.run(None, {'audio_input': input_data})
        
        print(f"âœ… ONNX æ¨ç†æˆåŠŸ")
        print(f"   è¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
        print(f"   åŸå§‹è¾“å‡º: {outputs[0][0][0]:.4f}")
        
        # åº”ç”¨ sigmoid
        raw_score = outputs[0][0][0]
        probability = 1.0 / (1.0 + np.exp(-raw_score))
        
        print()
        print(f"ğŸ“Š æ£€æµ‹ç»“æœ:")
        print(f"   åˆæˆæ¦‚ç‡: {probability:.4f}")
        print(f"   çœŸå®æ¦‚ç‡: {1 - probability:.4f}")
        
        if probability > 0.5:
            print(f"   ğŸ¯ åˆ¤æ–­: åˆæˆéŸ³é¢‘ (ç½®ä¿¡åº¦: {probability:.4f})")
        else:
            print(f"   ğŸ¯ åˆ¤æ–­: çœŸå®éŸ³é¢‘ (ç½®ä¿¡åº¦: {1 - probability:.4f})")
        
    except Exception as e:
        print(f"âŒ ONNX æ¨ç†å¤±è´¥: {e}")
        return False
    
    print()
    print(f"=" * 80)
    print(f"ğŸ‰ Synthesis Detection æ¨¡å‹åˆ›å»ºå®Œæˆï¼")
    print(f"=" * 80)
    print()
    print(f"ğŸ“ æ³¨æ„äº‹é¡¹:")
    print(f"   1. è¿™æ˜¯ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„æ¨¡å‹")
    print(f"   2. å®é™…ä½¿ç”¨éœ€è¦åœ¨çœŸå®/åˆæˆéŸ³é¢‘æ•°æ®é›†ä¸Šè®­ç»ƒ")
    print(f"   3. æ¨èæ•°æ®é›†: ASVspoof 2019/2021")
    print(f"   4. æˆ–è€…ä½¿ç”¨é¢„è®­ç»ƒçš„ RawNet2/AASIST æ¨¡å‹")
    print()
    
    return True


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ›å»º Synthesis Detection æ¨¡å‹")
    parser.add_argument(
        "--output-dir",
        type=str,
        default="/work/models",
        help="è¾“å‡ºç›®å½•"
    )
    
    args = parser.parse_args()
    
    success = create_synthesis_model(args.output_dir)
    
    sys.exit(0 if success else 1)

