# ç«‹å³æ‰§è¡Œ - AIæ¨¡å‹éƒ¨ç½²

## âœ… å·²å®Œæˆçš„å·¥ä½œ

1. âœ… åˆ é™¤æ‰€æœ‰æ¨¡æ‹Ÿ/é™çº§é€»è¾‘
2. âœ… åˆ›å»ºPythonæ¨ç†æœåŠ¡ (`Dockerfile.inference`, `inference_server.py`)
3. âœ… åˆ›å»ºæ¨¡å‹ä¸‹è½½è„šæœ¬ (`download_all_models.sh`)
4. âœ… æ›´æ–°AIæœåŠ¡è°ƒç”¨Pythonæ¨ç†
5. âœ… æ›´æ–°docker-compose.ymlé…ç½®

## ğŸš€ ç«‹å³æ‰§è¡Œä»¥ä¸‹å‘½ä»¤

### æ­¥éª¤1ï¼šä¸‹è½½æ‰€æœ‰AIæ¨¡å‹ï¼ˆçº¦1.3GBï¼‰

```bash
cd /root/meeting-system-server/meeting-system

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p /models/{speech_recognition,emotion_detection,text_summarization,audio_denoising,video_enhancement,audio_deepfake,face_deepfake}

# å®‰è£…Pythonä¾èµ–
pip3 install huggingface_hub transformers torch

# ä¸‹è½½æ¨¡å‹ï¼ˆè¿™å°†éœ€è¦20-30åˆ†é’Ÿï¼‰
python3 << 'EOF'
from huggingface_hub import snapshot_download

models = [
    ("openai/whisper-tiny", "/models/speech_recognition"),
    ("j-hartmann/emotion-english-distilroberta-base", "/models/emotion_detection"),
    ("sshleifer/distilbart-cnn-6-6", "/models/text_summarization"),
    ("speechbrain/sepformer-wham", "/models/audio_denoising"),
    ("caidas/swin2SR-classical-sr-x2-64", "/models/video_enhancement"),
    ("microsoft/wavlm-base-plus", "/models/audio_deepfake"),
    ("google/vit-base-patch16-224", "/models/face_deepfake"),
]

for model_id, path in models:
    print(f"\nä¸‹è½½: {model_id}")
    try:
        snapshot_download(repo_id=model_id, local_dir=path, local_dir_use_symlinks=False)
        print(f"âœ“ {model_id} å®Œæˆ")
    except Exception as e:
        print(f"âœ— {model_id} å¤±è´¥: {e}")

print("\næ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
EOF

# éªŒè¯ä¸‹è½½
du -sh /models/*
```

### æ­¥éª¤2ï¼šæ„å»ºå¹¶å¯åŠ¨Pythonæ¨ç†æœåŠ¡

```bash
cd /root/meeting-system-server/meeting-system

# æ„å»ºPythonæ¨ç†æœåŠ¡
docker-compose build python-inference

# å¯åŠ¨æœåŠ¡
docker-compose up -d python-inference

# æ£€æŸ¥çŠ¶æ€
docker-compose ps python-inference
docker-compose logs python-inference
```

### æ­¥éª¤3ï¼šé‡æ–°æ„å»ºå¹¶å¯åŠ¨AIæœåŠ¡

```bash
# é‡æ–°æ„å»ºAIæœåŠ¡
docker-compose build ai-service

# é‡å¯AIæœåŠ¡
docker-compose up -d ai-service

# æ£€æŸ¥çŠ¶æ€
docker-compose ps ai-service
docker-compose logs --tail=50 ai-service
```

### æ­¥éª¤4ï¼šè¿è¡ŒE2Eæµ‹è¯•

```bash
cd /root/meeting-system-server/meeting-system/backend/tests

# è¿è¡Œå®Œæ•´æµ‹è¯•
go test -v -run TestE2EIntegration

# é¢„æœŸï¼šæ‰€æœ‰AIæ¨¡å‹æµ‹è¯•é€šè¿‡ï¼ŒæˆåŠŸç‡100%
```

## ğŸ” éªŒè¯å‘½ä»¤

```bash
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹è½½
ls -lah /models/
du -sh /models/*

# æ£€æŸ¥Pythonæ¨ç†å®¹å™¨
docker exec meeting-python-inference ls -lah /models/

# æµ‹è¯•AIæœåŠ¡
curl http://localhost:8800/api/v1/models | python3 -m json.tool

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker-compose logs -f ai-service
docker-compose logs -f python-inference
```

## âš ï¸ é‡è¦æç¤º

- æ¨¡å‹ä¸‹è½½éœ€è¦20-30åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘2GBï¼‰
- å¦‚æœGPUä¸å¯ç”¨ï¼Œç¼–è¾‘docker-compose.ymlåˆ é™¤`runtime: nvidia`è¡Œ
- æ‰€æœ‰æ¨ç†å¿…é¡»ä½¿ç”¨çœŸå®æ¨¡å‹ï¼Œä¸å…è®¸ä»»ä½•æ¨¡æ‹Ÿ

## ğŸ“Š é¢„æœŸç»“æœ

E2Eæµ‹è¯•è¾“å‡ºåº”è¯¥æ˜¾ç¤ºï¼š

```
=== æ­¥éª¤7: AIæœåŠ¡å®Œæ•´æµ‹è¯• ===
âœ“ æ‰¾åˆ° 5 ä¸ªAIæ¨¡å‹
[1/5] æµ‹è¯•æ¨¡å‹: Audio Denoising Model - âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸ
[2/5] æµ‹è¯•æ¨¡å‹: Video Enhancement Model - âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸ
[3/5] æµ‹è¯•æ¨¡å‹: Speech Recognition Model - âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸ
[4/5] æµ‹è¯•æ¨¡å‹: Text Summarization Model - âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸ
[5/5] æµ‹è¯•æ¨¡å‹: Emotion Detection Model - âœ“ æ¨¡å‹æµ‹è¯•æˆåŠŸ

æ€»æ¨¡å‹æ•°: 5
æµ‹è¯•æˆåŠŸ: 5
æµ‹è¯•å¤±è´¥: 0
æˆåŠŸç‡: 100.0%

ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼
```

