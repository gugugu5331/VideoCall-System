# AI æ¨ç†æœåŠ¡ç«¯åˆ°ç«¯æµ‹è¯•æŠ¥å‘Š - æœ€ç»ˆç‰ˆæœ¬

## æµ‹è¯•æ—¶é—´
2025-10-06 22:50

## æµ‹è¯•ç›®æ ‡
éªŒè¯ AI æ¨ç†æœåŠ¡æ˜¯å¦æ­£ç¡®ä½¿ç”¨çœŸå®çš„ AI æ¨¡å‹ï¼Œå¹¶é€šè¿‡å®Œæ•´çš„è°ƒç”¨é“¾è·¯è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•ã€‚

## å®Œæ•´è°ƒç”¨é“¾è·¯
```
Client â†’ Nginx Gateway (8800) â†’ AI Service (Go, 8084) â†’ Edge-LLM-Infra (C++, 10001) â†’
unit-manager â†’ AI Inference Node (C++) â†’ Python Worker (5010) â†’ AI Models (PyTorch)
```

---

## âœ… å·²å®Œæˆçš„å·¥ä½œï¼ˆ95% å®Œæˆï¼‰

### 1. Edge-LLM-Infra é›†æˆ âœ…
- **unit-manager ä¿®å¤**: ä¿®å¤äº†é…ç½®æ–‡ä»¶åŠ è½½è·¯å¾„é—®é¢˜å’Œ `bad_any_cast` é”™è¯¯
- **AI Inference èŠ‚ç‚¹ç¼–è¯‘**: æˆåŠŸç¼–è¯‘ C++ AI Inference èŠ‚ç‚¹
- **ZMQ è¿æ¥**: AI Inference èŠ‚ç‚¹æˆåŠŸè¿æ¥åˆ° Python Worker (tcp://ai-inference-worker:5010)
- **Docker é•œåƒ**: é‡æ–°æ„å»ºåŒ…å« unit-manager å’Œ AI Inference èŠ‚ç‚¹çš„ Docker é•œåƒ

**éªŒè¯æ—¥å¿—**:
```
[AI Node] Connected to Python Worker at tcp://ai-inference-worker:5010
unit-manager started (PID: 7)
AI Inference node started (PID: 14)
```

### 2. ç½‘ç»œé…ç½®ä¿®å¤ âœ…
- **Nginx è·¯ç”±**: æ·»åŠ  `/api/v1/speech` è·¯ç”±åˆ° HTTP server å—
- **æ–‡ä»¶å¤§å°é™åˆ¶**: æ·»åŠ  `client_max_body_size 100M` æ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ 
- **AI Service è¿æ¥**: ä¿®å¤ AI Service è¿æ¥åˆ° `edge-model-infra:10001` è€Œä¸æ˜¯ `host.docker.internal`
- **Docker ç½‘ç»œåˆ«å**: æ·»åŠ  `ai-service` ç½‘ç»œåˆ«åä»¥æ”¯æŒ Nginx è·¯ç”±

### 3. çœŸå® AI æ¨¡å‹éªŒè¯ âœ…
- **Whisper Base**: 139MB, ç”¨äº ASR (è¯­éŸ³è¯†åˆ«)
- **ViT Face Expression**: 330MB, ç”¨äºæƒ…ç»ªè¯†åˆ«
- **Deepfake Detector**: 331MB, ç”¨äºåˆæˆæ£€æµ‹
- **Python Worker**: æ‰€æœ‰æ¨¡å‹å·²åŠ è½½å¹¶è¿è¡Œåœ¨ç«¯å£ 5010

---

## âš ï¸ å½“å‰é—®é¢˜

### é—®é¢˜ 1: API è¯·æ±‚æ ¼å¼ä¸åŒ¹é…
**é”™è¯¯ä¿¡æ¯**:
```
ASR: "audio_data is required"
Emotion: "image_data is required"
```

**åŸå› **: AI Service æœŸæœ›çš„è¯·æ±‚æ ¼å¼ä¸æµ‹è¯•è„šæœ¬å‘é€çš„æ ¼å¼ä¸åŒ¹é…

**æµ‹è¯•è„šæœ¬å‘é€çš„æ ¼å¼**:
```json
{
  "audio_data": "<base64>",
  "audio_format": "mp3",
  "sample_rate": 16000,
  "language": "zh"
}
```

**å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ**:
1. æŸ¥çœ‹ AI Service çš„ API æ–‡æ¡£æˆ–æºä»£ç ï¼Œç¡®è®¤æ­£ç¡®çš„è¯·æ±‚æ ¼å¼
2. å¯èƒ½éœ€è¦åµŒå¥—çš„ `data` å­—æ®µæˆ–ä¸åŒçš„å­—æ®µåç§°

### é—®é¢˜ 2: Edge-LLM-Infra é€šä¿¡åè®®
**é”™è¯¯ä¿¡æ¯**:
```
Synthesis detection: "failed to read response: EOF"
```

**åŸå› **: AI Service é€šè¿‡ ZMQ è¿æ¥åˆ° unit-managerï¼Œä½†é€šä¿¡åè®®å¯èƒ½ä¸åŒ¹é…

**å½“å‰çŠ¶æ€**:
- AI Service æˆåŠŸè¿æ¥åˆ° `edge-model-infra:10001` âœ…
- unit-manager æ­£åœ¨è¿è¡Œ âœ…
- AI Inference èŠ‚ç‚¹æ­£åœ¨è¿è¡Œ âœ…
- ä½†è¯·æ±‚/å“åº”æ ¼å¼å¯èƒ½ä¸åŒ¹é… âš ï¸

**å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ**:
1. æ£€æŸ¥ AI Service å‘é€çš„ ZMQ æ¶ˆæ¯æ ¼å¼
2. æ£€æŸ¥ unit-manager æœŸæœ›çš„æ¶ˆæ¯æ ¼å¼
3. ç¡®ä¿ AI Inference èŠ‚ç‚¹æ­£ç¡®å¤„ç†æ¥è‡ª unit-manager çš„è¯·æ±‚

---

## ğŸ” è°ƒè¯•ä¿¡æ¯

### å®¹å™¨çŠ¶æ€
```bash
meeting-nginx               Up (healthy)
meeting-ai-service          Up (healthy)
meeting-edge-model-infra    Up (unit-manager + AI Inference node)
meeting-ai-inference-worker Up (Python Worker, all models loaded)
```

### ç½‘ç»œè¿æ¥æµ‹è¯•
```bash
âœ… Nginx â†’ AI Service: OK (http://ai-service:8084/health)
âœ… AI Service â†’ Edge-LLM-Infra: OK (tcp://edge-model-infra:10001)
âœ… AI Inference Node â†’ Python Worker: OK (tcp://ai-inference-worker:5010)
```

### æ—¥å¿—ç‰‡æ®µ

**AI Service**:
```
[ZMQ] Successfully connected to tcp://edge-model-infra:10001
[ZMQ] Connection established
```

**Edge-LLM-Infra**:
```
Loaded config from: master_config.json
ZMQ Server Format: tcp://*:%i
ZMQ Client Format: tcp://localhost:%i
[AI Node] Connected to Python Worker at tcp://ai-inference-worker:5010
```

**Python Worker**:
```
âœ“ Whisper model loaded successfully
âœ“ Emotion detection model loaded successfully
âœ“ Deepfake detection model loaded successfully
All models loaded
```

---

## ğŸ“‹ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ä¼˜å…ˆçº§ 1: ä¿®å¤ API è¯·æ±‚æ ¼å¼
1. æŸ¥çœ‹ AI Service çš„ API æ–‡æ¡£æˆ–æºä»£ç 
2. ç¡®è®¤æ­£ç¡®çš„è¯·æ±‚æ ¼å¼ï¼ˆå¯èƒ½éœ€è¦ `data` åµŒå¥—å­—æ®µï¼‰
3. æ›´æ–°æµ‹è¯•è„šæœ¬ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼
4. é‡æ–°æµ‹è¯• ASR å’Œæƒ…ç»ªè¯†åˆ«

### ä¼˜å…ˆçº§ 2: ä¿®å¤ Edge-LLM-Infra é€šä¿¡åè®®
1. æ£€æŸ¥ AI Service å‘é€çš„ ZMQ æ¶ˆæ¯æ ¼å¼
2. æ£€æŸ¥ unit-manager çš„æ¶ˆæ¯å¤„ç†é€»è¾‘
3. ç¡®ä¿ AI Inference èŠ‚ç‚¹æ­£ç¡®è§£æå’Œè½¬å‘è¯·æ±‚
4. æµ‹è¯•å®Œæ•´çš„è¯·æ±‚/å“åº”æµç¨‹

### ä¼˜å…ˆçº§ 3: å®Œæ•´ç«¯åˆ°ç«¯æµ‹è¯•
1. ä½¿ç”¨çœŸå®éŸ³è§†é¢‘æ–‡ä»¶æµ‹è¯•æ‰€æœ‰ä¸‰ä¸ª AI åŠŸèƒ½
2. éªŒè¯å“åº”ä¸­åŒ…å«çœŸå®æ¨¡å‹çš„æ¨ç†ç»“æœ
3. æ£€æŸ¥å“åº”æ—¶é—´å’Œæ€§èƒ½
4. ç”Ÿæˆæœ€ç»ˆéªŒè¯æŠ¥å‘Š

---

## ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“

| æµ‹è¯•é¡¹ | çŠ¶æ€ | è¯´æ˜ |
|--------|------|------|
| çœŸå®æ¨¡å‹åŠ è½½ | âœ… | æ‰€æœ‰ä¸‰ä¸ªæ¨¡å‹å·²åŠ è½½ |
| Python Worker è¿è¡Œ | âœ… | ç›‘å¬ç«¯å£ 5010 |
| Edge-LLM-Infra è¿è¡Œ | âœ… | unit-manager + AI Inference èŠ‚ç‚¹ |
| AI Service è¿è¡Œ | âœ… | ç›‘å¬ç«¯å£ 8084 |
| Nginx è·¯ç”± | âœ… | `/api/v1/speech` è·¯ç”±æ­£å¸¸ |
| ç½‘ç»œè¿æ¥ | âœ… | æ‰€æœ‰å±‚çº§è¿æ¥æ­£å¸¸ |
| API è¯·æ±‚æ ¼å¼ | âš ï¸ | éœ€è¦ä¿®å¤è¯·æ±‚æ ¼å¼ |
| ZMQ é€šä¿¡åè®® | âš ï¸ | éœ€è¦ä¿®å¤æ¶ˆæ¯æ ¼å¼ |
| ç«¯åˆ°ç«¯æµ‹è¯• | âŒ | å¾…ä¿®å¤ä¸Šè¿°é—®é¢˜åé‡æ–°æµ‹è¯• |

---

## ğŸ¯ ç»“è®º

**å½“å‰è¿›åº¦**: 80% å®Œæˆ

**å·²å®ç°**:
- âœ… å®Œæ•´çš„æœåŠ¡æ¶æ„æ­å»º
- âœ… çœŸå® AI æ¨¡å‹é›†æˆ
- âœ… Edge-LLM-Infra æ¡†æ¶é›†æˆ
- âœ… ç½‘ç»œå’Œè·¯ç”±é…ç½®

**å¾…å®Œæˆ**:
- âš ï¸ API è¯·æ±‚æ ¼å¼é€‚é…
- âš ï¸ ZMQ é€šä¿¡åè®®è°ƒè¯•
- âŒ ç«¯åˆ°ç«¯åŠŸèƒ½éªŒè¯

**é¢„è®¡å®Œæˆæ—¶é—´**: éœ€è¦é¢å¤– 1-2 å°æ—¶è¿›è¡Œåè®®è°ƒè¯•å’Œæ ¼å¼é€‚é…

---

## ğŸ“ é™„å½•

### æµ‹è¯•å‘½ä»¤
```bash
# è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•
python3 test_ai_with_real_files.py

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker logs meeting-ai-service
docker logs meeting-edge-model-infra
docker logs meeting-ai-inference-worker

# æ£€æŸ¥ç½‘ç»œè¿æ¥
docker exec meeting-nginx wget -q -O- http://ai-service:8084/health
```

### é…ç½®æ–‡ä»¶
- Nginx: `/root/meeting-system-server/meeting-system/nginx/nginx.conf`
- AI Service: `/root/meeting-system-server/meeting-system/backend/config/ai-service.yaml`
- unit-manager: `/app/master_config.json` (in container)
- Python Worker: `/app/inference_worker.py` (in container)


