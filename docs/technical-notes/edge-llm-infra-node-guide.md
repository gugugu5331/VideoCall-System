# Edge-LLM-InfraèŠ‚ç‚¹å®ç°æŒ‡å—

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¶é—´**: 2025-09-29  
**æœ€åæ›´æ–°**: 2025-09-29  
**ç»´æŠ¤è€…**: AIå›¢é˜Ÿ  
**æ–‡æ¡£ç±»å‹**: æŠ€æœ¯ç¬”è®°  

---

## ğŸ“‹ æ–‡æ¡£æ¦‚è§ˆ

### ç›®çš„
æœ¬æ–‡æ¡£æä¾›Edge-LLM-Infraæ¡†æ¶ä¸­AIæ¨ç†èŠ‚ç‚¹çš„å®ç°æŒ‡å—ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹å¼€å‘ã€éƒ¨ç½²å’Œé›†æˆæ–¹æ³•ã€‚

### è¯»è€…å¯¹è±¡
- C++å¼€å‘å·¥ç¨‹å¸ˆ
- AIç®—æ³•å·¥ç¨‹å¸ˆ
- ç³»ç»Ÿé›†æˆå·¥ç¨‹å¸ˆ

### å…ˆå†³æ¡ä»¶
- ç†Ÿæ‚‰C++ç¼–ç¨‹
- äº†è§£æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½²
- å…·å¤‡åˆ†å¸ƒå¼ç³»ç»ŸåŸºç¡€çŸ¥è¯†

---

## ğŸ“– Edge-LLM-InfraæŠ€æœ¯æ¶æ„

### æ ¸å¿ƒç»„ä»¶

#### 1. StackFlowæ¡†æ¶
```cpp
class StackFlow {
public:
    // æ ‡å‡†ç”Ÿå‘½å‘¨æœŸæ¥å£
    virtual int setup(const std::string& work_id, const std::string& object, const std::string& data) = 0;
    virtual int exit(const std::string& work_id, const std::string& object, const std::string& data) = 0;
    
    // äº‹ä»¶å¤„ç†
    eventpp::EventQueue<int, void(const std::shared_ptr<void> &)> event_queue_;
    
    // é€šä¿¡ç®¡ç†
    std::unordered_map<int, std::shared_ptr<llm_channel_obj>> llm_task_channel_;
};
```

#### 2. Channelç®¡ç†
- **ZMQè¿æ¥ç®¡ç†**: æ”¯æŒPUB/SUBã€PUSH/PULLã€REQ/REPæ¨¡å¼
- **åŠ¨æ€URLç»‘å®š**: è¿è¡Œæ—¶é…ç½®è¿æ¥å‚æ•°
- **åè®®æ ‡å‡†åŒ–**: JSONæ ¼å¼æ¶ˆæ¯åè®®

#### 3. unit-manager
- **æœåŠ¡å‘ç°**: è‡ªåŠ¨æ³¨å†Œå’Œå‘ç°AIèŠ‚ç‚¹
- **ä»»åŠ¡åˆ†å‘**: æŒ‰actionè·¯ç”±ä»»åŠ¡åˆ°å¯¹åº”èŠ‚ç‚¹
- **åè®®è½¬æ¢**: TCP/ZMQåè®®ç½‘å…³

## ğŸ—ï¸ èŠ‚ç‚¹å®ç°æ¨¡å¼

### åŸºç¡€èŠ‚ç‚¹æ¨¡æ¿
```cpp
#include "StackFlow.h"

class MyAINode : public StackFlows::StackFlow {
public:
    MyAINode(const std::string& unit_name) : StackFlow(unit_name) {}
    
    int setup(const std::string& work_id, const std::string& object, const std::string& data) override {
        // 1. è§£æé…ç½®
        // 2. åŠ è½½æ¨¡å‹
        // 3. åˆå§‹åŒ–æ¨ç†ç¯å¢ƒ
        return 0;
    }
    
    int exit(const std::string& work_id, const std::string& object, const std::string& data) override {
        // 1. æ¸…ç†èµ„æº
        // 2. ä¿å­˜çŠ¶æ€
        // 3. é‡Šæ”¾æ¨¡å‹
        return 0;
    }
    
private:
    // AIæ¨¡å‹å’Œæ¨ç†ç›¸å…³æˆå‘˜
    std::shared_ptr<AIModel> model_;
    std::queue<InferenceTask> task_queue_;
};
```

### ä¼šè®®AIèŠ‚ç‚¹ç¤ºä¾‹
```cpp
class MeetingAINode : public StackFlows::StackFlow {
public:
    MeetingAINode(const std::string& unit_name) : StackFlow(unit_name) {}
    
    // è¯­éŸ³è¯†åˆ«ä»»åŠ¡
    void processSpeechRecognition(const std::string& audio_data) {
        // 1. éŸ³é¢‘é¢„å¤„ç†
        // 2. æ¨¡å‹æ¨ç†
        // 3. ç»“æœåå¤„ç†
        // 4. å‘é€ç»“æœ
    }
    
    // æƒ…ç»ªè¯†åˆ«ä»»åŠ¡
    void processEmotionDetection(const std::string& video_frame) {
        // 1. å›¾åƒé¢„å¤„ç†
        // 2. æƒ…ç»ªæ¨ç†
        // 3. ç»“æœæ•´åˆ
        // 4. è¿”å›æƒ…ç»ªæ•°æ®
    }
};
```

## ğŸ”§ å¼€å‘æœ€ä½³å®è·µ

### 1. å†…å­˜ç®¡ç†
```cpp
// ä½¿ç”¨æ™ºèƒ½æŒ‡é’ˆç®¡ç†èµ„æº
std::shared_ptr<Model> model = std::make_shared<Model>();

// é¿å…å¾ªç¯å¼•ç”¨
std::weak_ptr<Channel> channel_ref = channel_;
```

### 2. å¼‚å¸¸å¤„ç†
```cpp
try {
    // AIæ¨ç†ä»£ç 
    auto result = model->infer(input);
    return createSuccessResponse(result);
} catch (const std::exception& e) {
    LOG(ERROR) << "æ¨ç†å¤±è´¥: " << e.what();
    return createErrorResponse(e.what());
}
```

### 3. æ€§èƒ½ä¼˜åŒ–
```cpp
// æ‰¹å¤„ç†æ¨ç†
std::vector<Input> batch_inputs;
if (batch_inputs.size() >= batch_size_) {
    auto results = model->batch_infer(batch_inputs);
    processBatchResults(results);
}

// GPUå†…å­˜æ± 
class GPUMemoryPool {
    std::queue<void*> free_blocks_;
    size_t block_size_;
public:
    void* allocate() { /* ... */ }
    void deallocate(void* ptr) { /* ... */ }
};
```

## ğŸ“Š æ¶ˆæ¯åè®®æ ¼å¼

### æ ‡å‡†è¯·æ±‚æ ¼å¼
```json
{
    "request_id": "req_123456789",
    "work_id": "meeting_ai_001",
    "object": "speech_recognition",
    "data": {
        "audio_format": "pcm",
        "sample_rate": 16000,
        "channels": 1,
        "audio_data": "base64_encoded_audio_data"
    }
}
```

### æ ‡å‡†å“åº”æ ¼å¼
```json
{
    "request_id": "req_123456789",
    "work_id": "meeting_ai_001", 
    "object": "speech_recognition",
    "data": {
        "text": "è¯†åˆ«çš„æ–‡å­—å†…å®¹",
        "confidence": 0.95,
        "language": "zh-CN",
        "timestamp": 1696003200000
    },
    "error": null
}
```

## ğŸš€ éƒ¨ç½²å’Œé…ç½®

### èŠ‚ç‚¹é…ç½®æ–‡ä»¶
```yaml
# ai_node_config.yaml
node:
  unit_name: "meeting_ai_node"
  max_workers: 4
  max_queue_size: 1000
  
models:
  speech_recognition:
    path: "./models/speech_recognition.model"
    device: "cuda:0"
    
  emotion_detection:
    path: "./models/emotion_detection.model"
    device: "cuda:1"
    
zmq:
  publisher_url: "tcp://*:5555"
  subscriber_url: "tcp://localhost:5556"
  
unit_manager:
  endpoint: "tcp://localhost:8888"
  heartbeat_interval: 30
```

### Dockeréƒ¨ç½²
```dockerfile
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# å®‰è£…ä¾èµ–
RUN apt-get update && apt-get install -y \
    cmake \
    libzmq3-dev \
    libopencv-dev

# å¤åˆ¶ä»£ç å’Œæ¨¡å‹
COPY src/ /app/src/
COPY models/ /app/models/
COPY config/ /app/config/

# ç¼–è¯‘
WORKDIR /app
RUN mkdir build && cd build && \
    cmake .. && make -j8

# å¯åŠ¨èŠ‚ç‚¹
CMD ["./build/meeting_ai_node", "--config", "/app/config/ai_node_config.yaml"]
```

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### æ—¥å¿—é…ç½®
```cpp
#include <glog/glog.h>

// åˆå§‹åŒ–æ—¥å¿—
google::InitGoogleLogging("meeting_ai_node");
FLAGS_log_dir = "/var/log/ai_nodes/";
FLAGS_max_log_size = 100; // MB

// æ—¥å¿—è®°å½•
LOG(INFO) << "èŠ‚ç‚¹å¯åŠ¨æˆåŠŸ: " << unit_name_;
LOG(WARNING) << "é˜Ÿåˆ—æ¥è¿‘æ»¡è½½: " << queue_size_;
LOG(ERROR) << "æ¨ç†å¤±è´¥: " << error_msg;
```

### æ€§èƒ½ç›‘æ§
```cpp
class PerformanceMonitor {
public:
    void recordInferenceTime(const std::string& task_type, double time_ms) {
        std::lock_guard<std::mutex> lock(mutex_);
        inference_times_[task_type].push_back(time_ms);
    }
    
    double getAverageInferenceTime(const std::string& task_type) {
        // è®¡ç®—å¹³å‡æ¨ç†æ—¶é—´
    }
    
    void logMetrics() {
        LOG(INFO) << "å¤„ç†ä»»åŠ¡æ•°: " << processed_tasks_;
        LOG(INFO) << "å¹³å‡æ¨ç†æ—¶é—´: " << avg_inference_time_;
        LOG(INFO) << "å†…å­˜ä½¿ç”¨: " << memory_usage_mb_ << "MB";
    }
};
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹ä¼˜åŒ–
- **é‡åŒ–**: ä½¿ç”¨INT8é‡åŒ–å‡å°‘å†…å­˜å’Œè®¡ç®—
- **å‰ªæ**: ç§»é™¤ä¸é‡è¦çš„ç½‘ç»œè¿æ¥
- **è’¸é¦**: ç”¨å°æ¨¡å‹å­¦ä¹ å¤§æ¨¡å‹çŸ¥è¯†

### 2. ç³»ç»Ÿä¼˜åŒ–
- **NUMAç»‘å®š**: ä¼˜åŒ–CPUå†…å­˜è®¿é—®
- **GPUæµ**: é‡å è®¡ç®—å’Œå†…å­˜ä¼ è¾“
- **é¢„åˆ†é…**: é¿å…è¿è¡Œæ—¶å†…å­˜åˆ†é…

### 3. ç½‘ç»œä¼˜åŒ–
- **è¿æ¥æ± **: å¤ç”¨ZMQè¿æ¥
- **æ‰¹é‡ä¼ è¾“**: å‡å°‘ç½‘ç»œå¾€è¿”æ¬¡æ•°
- **å‹ç¼©**: å¯¹å¤§æ•°æ®è¿›è¡Œå‹ç¼©ä¼ è¾“

---

## ğŸ“ ç›¸å…³èµ„æº

### ç›¸å…³æ–‡æ¡£
- [ä¼šè®®ç³»ç»Ÿæ¶æ„è®¾è®¡](../architecture/meeting-system-architecture.md)
- [é¡¹ç›®çŠ¶æ€åˆ†ææŠ¥å‘Š](../progress-reports/2025-09-29-project-status-analysis.md)

### å¤–éƒ¨èµ„æº
- [ZeroMQ Guide](https://zguide.zeromq.org/)
- [ONNX Runtimeæ–‡æ¡£](https://onnxruntime.ai/)
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/)

### å·¥å…·å’Œä¾èµ–
- ZeroMQ: 4.3+
- OpenCV: 4.5+
- CUDA: 11.8+
- CMake: 3.16+

---

## ğŸ”„ å˜æ›´å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | å˜æ›´å†…å®¹ | å˜æ›´è€… |
|------|------|----------|--------|
| v1.0 | 2025-09-29 | åˆå§‹ç‰ˆæœ¬åˆ›å»ºï¼ŒåŸºäºç°æœ‰ä»£ç æ¡†æ¶ç¼–å†™ | AIå›¢é˜Ÿ |

---

## ğŸ“ è”ç³»ä¿¡æ¯

### æ–‡æ¡£ç»´æŠ¤è€…
- **å§“å**: AIå›¢é˜Ÿ
- **èŒè´£**: Edge-LLM-Infraå¼€å‘å’ŒAIèŠ‚ç‚¹å®ç°

### æŠ€æœ¯æ”¯æŒ
å¦‚æœ‰å…³äºAIèŠ‚ç‚¹å®ç°çš„é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
1. åˆ›å»ºGitHub Issue (æ ‡ç­¾: ai-infra)
2. åœ¨å›¢é˜Ÿåä½œå¹³å°è®¨è®º
3. å‚åŠ AIæŠ€æœ¯è¯„å®¡ä¼šè®®

---

**æ³¨æ„**: æœ¬æŒ‡å—åŸºäºå½“å‰æ¡†æ¶ç‰ˆæœ¬ï¼Œéšç€æŠ€æœ¯å‘å±•å¯èƒ½è¿›è¡Œæ›´æ–°ã€‚