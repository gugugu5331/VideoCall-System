#!/usr/bin/env python3
"""
VideoCall System - Edge-Model-Infra AIæ£€æµ‹æœåŠ¡é›†æˆéƒ¨ç½²
ä¸“é—¨ç”¨äºé›†æˆå’Œéƒ¨ç½²Edge-Model-Infra AIæ£€æµ‹æœåŠ¡
"""

import os
import sys
import subprocess
import json
import shutil
import logging
from pathlib import Path
from typing import Dict, List, Optional

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('edge_model_infra_deployment.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EdgeModelInfraIntegrator:
    """Edge-Model-Infra AIæ£€æµ‹æœåŠ¡é›†æˆå™¨"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.edge_infra_path = self.project_root / "Edge-Model-Infra"
        self.ai_detection_node_path = self.edge_infra_path / "node" / "ai-detection"
        self.unit_manager_path = self.edge_infra_path / "unit-manager"
        
    def check_edge_infra_availability(self) -> bool:
        """æ£€æŸ¥Edge-Model-Infraæ˜¯å¦å¯ç”¨"""
        logger.info("ğŸ” æ£€æŸ¥Edge-Model-Infraå¯ç”¨æ€§...")
        
        required_paths = [
            self.edge_infra_path,
            self.ai_detection_node_path,
            self.unit_manager_path,
            self.ai_detection_node_path / "CMakeLists.txt",
            self.ai_detection_node_path / "Dockerfile",
            self.edge_infra_path / "docker-compose.ai-detection.yml"
        ]
        
        for path in required_paths:
            if not path.exists():
                logger.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {path}")
                return False
            logger.info(f"âœ… æ‰¾åˆ°: {path}")
        
        logger.info("âœ… Edge-Model-Infraç»“æ„æ£€æŸ¥é€šè¿‡")
        return True
    
    def prepare_edge_infra_environment(self) -> bool:
        """å‡†å¤‡Edge-Model-Infraç¯å¢ƒ"""
        logger.info("ğŸ”§ å‡†å¤‡Edge-Model-Infraç¯å¢ƒ...")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        dirs_to_create = [
            "/tmp/llm",
            "/tmp/detection_uploads",
            self.project_root / "storage" / "detection",
            self.ai_detection_node_path / "models",
            self.ai_detection_node_path / "build"
        ]
        
        for dir_path in dirs_to_create:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_path}")
        
        # æ£€æŸ¥å¹¶åˆ›å»ºé…ç½®æ–‡ä»¶
        self.create_detection_config()
        self.create_unit_manager_config()
        
        return True
    
    def create_detection_config(self):
        """åˆ›å»ºAIæ£€æµ‹é…ç½®æ–‡ä»¶"""
        config_path = self.ai_detection_node_path / "config" / "detection_config.json"
        config_path.parent.mkdir(exist_ok=True)
        
        if not config_path.exists():
            config = {
                "detection": {
                    "face_swap": {
                        "enabled": True,
                        "model_path": "/app/models/face_swap_detection.onnx",
                        "threshold": 0.8,
                        "batch_size": 4
                    },
                    "voice_synthesis": {
                        "enabled": True,
                        "model_path": "/app/models/voice_synthesis_detection.pt",
                        "threshold": 0.7,
                        "sample_rate": 16000
                    },
                    "content_analysis": {
                        "enabled": True,
                        "max_file_size": "100MB",
                        "supported_formats": ["mp4", "avi", "mov", "wav", "mp3"]
                    }
                },
                "network": {
                    "zmq_port": 5555,
                    "http_port": 5000,
                    "max_connections": 100
                },
                "performance": {
                    "gpu_enabled": False,
                    "num_threads": 4,
                    "queue_size": 1000
                },
                "logging": {
                    "level": "INFO",
                    "file": "/app/logs/detection.log"
                }
            }
            
            with open(config_path, 'w') as f:
                json.dump(config, f, indent=2)
            
            logger.info(f"âœ… åˆ›å»ºAIæ£€æµ‹é…ç½®: {config_path}")
    
    def create_unit_manager_config(self):
        """åˆ›å»ºUnit Manageré…ç½®æ–‡ä»¶"""
        config_path = self.unit_manager_path / "master_config.json"
        
        if not config_path.exists():
            config = {
                "master": {
                    "port": 10001,
                    "max_workers": 10,
                    "heartbeat_interval": 30
                },
                "nodes": [
                    {
                        "name": "ai-detection",
                        "type": "ai_detection",
                        "endpoint": "tcp://edge-ai-detection:5555",
                        "capabilities": ["face_swap_detection", "voice_synthesis_detection"],
                        "max_concurrent_tasks": 5
                    }
                ],
                "load_balancing": {
                    "strategy": "round_robin",
                    "health_check_interval": 10
                },
                "logging": {
                    "level": "INFO",
                    "file": "/app/logs/unit_manager.log"
                }
            }
            
            with open(config_path, 'w') as f:
                json.dump(config, f, indent=2)
            
            logger.info(f"âœ… åˆ›å»ºUnit Manageré…ç½®: {config_path}")
    
    def build_edge_infra_components(self) -> bool:
        """æ„å»ºEdge-Model-Infraç»„ä»¶"""
        logger.info("ğŸ”¨ æ„å»ºEdge-Model-Infraç»„ä»¶...")
        
        # æ„å»ºAIæ£€æµ‹èŠ‚ç‚¹
        if not self.build_ai_detection_node():
            return False
        
        # æ„å»ºUnit Manager
        if not self.build_unit_manager():
            return False
        
        return True
    
    def build_ai_detection_node(self) -> bool:
        """æ„å»ºAIæ£€æµ‹èŠ‚ç‚¹"""
        logger.info("ğŸ¤– æ„å»ºAIæ£€æµ‹èŠ‚ç‚¹...")
        
        build_dir = self.ai_detection_node_path / "build"
        
        try:
            # æ¸…ç†æ„å»ºç›®å½•
            if build_dir.exists():
                shutil.rmtree(build_dir)
            build_dir.mkdir()
            
            # CMakeé…ç½®
            cmake_cmd = [
                "cmake", "..", 
                "-DCMAKE_BUILD_TYPE=Release",
                "-DCMAKE_CXX_STANDARD=17"
            ]
            
            subprocess.run(cmake_cmd, cwd=build_dir, check=True)
            
            # æ„å»º
            make_cmd = ["make", "-j", str(os.cpu_count() or 4)]
            subprocess.run(make_cmd, cwd=build_dir, check=True)
            
            logger.info("âœ… AIæ£€æµ‹èŠ‚ç‚¹æ„å»ºæˆåŠŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ AIæ£€æµ‹èŠ‚ç‚¹æ„å»ºå¤±è´¥: {e}")
            return False
    
    def build_unit_manager(self) -> bool:
        """æ„å»ºUnit Manager"""
        logger.info("âš™ï¸ æ„å»ºUnit Manager...")
        
        build_dir = self.unit_manager_path / "build"
        
        try:
            # æ¸…ç†æ„å»ºç›®å½•
            if build_dir.exists():
                shutil.rmtree(build_dir)
            build_dir.mkdir()
            
            # CMakeé…ç½®
            cmake_cmd = [
                "cmake", "..", 
                "-DCMAKE_BUILD_TYPE=Release",
                "-DCMAKE_CXX_STANDARD=17"
            ]
            
            subprocess.run(cmake_cmd, cwd=build_dir, check=True)
            
            # æ„å»º
            make_cmd = ["make", "-j", str(os.cpu_count() or 4)]
            subprocess.run(make_cmd, cwd=build_dir, check=True)
            
            logger.info("âœ… Unit Manageræ„å»ºæˆåŠŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ Unit Manageræ„å»ºå¤±è´¥: {e}")
            return False
    
    def deploy_with_docker(self) -> bool:
        """ä½¿ç”¨Dockeréƒ¨ç½²Edge-Model-Infra"""
        logger.info("ğŸ³ ä½¿ç”¨Dockeréƒ¨ç½²Edge-Model-Infra...")
        
        try:
            # ä½¿ç”¨Edge-Model-Infraçš„docker-composeæ–‡ä»¶
            compose_file = self.edge_infra_path / "docker-compose.ai-detection.yml"
            
            # åœæ­¢ç°æœ‰æœåŠ¡
            subprocess.run([
                "docker-compose", "-f", str(compose_file), "down"
            ], cwd=self.edge_infra_path)
            
            # æ„å»ºå¹¶å¯åŠ¨æœåŠ¡
            subprocess.run([
                "docker-compose", "-f", str(compose_file), "up", "--build", "-d"
            ], cwd=self.edge_infra_path, check=True)
            
            logger.info("âœ… Edge-Model-Infra Dockeréƒ¨ç½²æˆåŠŸ")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ Edge-Model-Infra Dockeréƒ¨ç½²å¤±è´¥: {e}")
            return False
    
    def integrate_with_backend_services(self) -> bool:
        """ä¸åç«¯æœåŠ¡é›†æˆ"""
        logger.info("ğŸ”— ä¸åç«¯æœåŠ¡é›†æˆ...")
        
        # åˆ›å»ºé›†æˆé…ç½®
        integration_config = {
            "edge_model_infra": {
                "unit_manager_url": "http://localhost:10001",
                "ai_detection_url": "http://localhost:5000",
                "enabled": True,
                "fallback_to_legacy": True
            },
            "detection_services": {
                "face_swap_detection": {
                    "endpoint": "/api/v1/detect/face-swap",
                    "timeout": 30,
                    "retry_count": 3
                },
                "voice_synthesis_detection": {
                    "endpoint": "/api/v1/detect/voice-synthesis",
                    "timeout": 45,
                    "retry_count": 3
                }
            }
        }
        
        # ä¿å­˜é›†æˆé…ç½®
        config_path = self.project_root / "config" / "edge_model_infra_integration.json"
        config_path.parent.mkdir(exist_ok=True)
        
        with open(config_path, 'w') as f:
            json.dump(integration_config, f, indent=2)
        
        logger.info(f"âœ… é›†æˆé…ç½®å·²ä¿å­˜: {config_path}")
        return True
    
    def test_integration(self) -> bool:
        """æµ‹è¯•é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•Edge-Model-Infraé›†æˆ...")
        
        try:
            # æµ‹è¯•Unit Managerè¿æ¥
            import requests
            
            unit_manager_url = "http://localhost:10001/health"
            response = requests.get(unit_manager_url, timeout=10)
            
            if response.status_code == 200:
                logger.info("âœ… Unit Managerè¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning(f"âš ï¸ Unit Managerå“åº”å¼‚å¸¸: {response.status_code}")
            
            # æµ‹è¯•AIæ£€æµ‹èŠ‚ç‚¹
            ai_detection_url = "http://localhost:5000/health"
            response = requests.get(ai_detection_url, timeout=10)
            
            if response.status_code == 200:
                logger.info("âœ… AIæ£€æµ‹èŠ‚ç‚¹è¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning(f"âš ï¸ AIæ£€æµ‹èŠ‚ç‚¹å“åº”å¼‚å¸¸: {response.status_code}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def create_startup_scripts(self):
        """åˆ›å»ºå¯åŠ¨è„šæœ¬"""
        logger.info("ğŸ“ åˆ›å»ºå¯åŠ¨è„šæœ¬...")
        
        # WSLå¯åŠ¨è„šæœ¬
        wsl_startup_script = self.project_root / "scripts" / "start_edge_infra_wsl.sh"
        wsl_startup_script.parent.mkdir(exist_ok=True)
        
        wsl_script_content = f"""#!/bin/bash

# VideoCall System - Edge-Model-Infra WSLå¯åŠ¨è„šæœ¬

set -e

echo "ğŸš€ å¯åŠ¨Edge-Model-Infra AIæ£€æµ‹æœåŠ¡..."

# æ£€æŸ¥Dockeræ˜¯å¦è¿è¡Œ
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Dockeræœªè¿è¡Œï¼Œè¯·å…ˆå¯åŠ¨Docker"
    exit 1
fi

# è¿›å…¥Edge-Model-Infraç›®å½•
cd {self.edge_infra_path}

# åœæ­¢ç°æœ‰æœåŠ¡
echo "ğŸ›‘ åœæ­¢ç°æœ‰æœåŠ¡..."
docker-compose -f docker-compose.ai-detection.yml down

# å¯åŠ¨æœåŠ¡
echo "ğŸš€ å¯åŠ¨Edge-Model-InfraæœåŠ¡..."
docker-compose -f docker-compose.ai-detection.yml up --build -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ“Š æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose -f docker-compose.ai-detection.yml ps

echo "âœ… Edge-Model-Infraå¯åŠ¨å®Œæˆï¼"
echo "ğŸŒ Unit Manager: http://localhost:10001"
echo "ğŸ¤– AI Detection: http://localhost:5000"
"""
        
        with open(wsl_startup_script, 'w') as f:
            f.write(wsl_script_content)
        
        os.chmod(wsl_startup_script, 0o755)
        
        # Windows PowerShellè„šæœ¬
        ps_startup_script = self.project_root / "scripts" / "start_edge_infra_wsl.ps1"
        
        ps_script_content = f"""# VideoCall System - Edge-Model-Infra Windowså¯åŠ¨è„šæœ¬

Write-Host "ğŸš€ å¯åŠ¨Edge-Model-Infra AIæ£€æµ‹æœåŠ¡..." -ForegroundColor Green

# æ£€æŸ¥WSLæ˜¯å¦å¯ç”¨
try {{
    wsl --list --running | Out-Null
    Write-Host "âœ… WSLå¯ç”¨" -ForegroundColor Green
}} catch {{
    Write-Host "âŒ WSLä¸å¯ç”¨ï¼Œè¯·å…ˆå®‰è£…å¹¶å¯åŠ¨WSL" -ForegroundColor Red
    exit 1
}}

# åœ¨WSLä¸­å¯åŠ¨Edge-Model-Infra
Write-Host "ğŸ§ åœ¨WSLä¸­å¯åŠ¨Edge-Model-Infra..." -ForegroundColor Cyan
wsl bash -c "cd {self.edge_infra_path} && ./scripts/start_edge_infra_wsl.sh"

Write-Host "âœ… Edge-Model-Infraå¯åŠ¨å®Œæˆï¼" -ForegroundColor Green
Write-Host "ğŸŒ Unit Manager: http://localhost:10001" -ForegroundColor Yellow
Write-Host "ğŸ¤– AI Detection: http://localhost:5000" -ForegroundColor Yellow
"""
        
        with open(ps_startup_script, 'w') as f:
            f.write(ps_script_content)
        
        logger.info("âœ… å¯åŠ¨è„šæœ¬åˆ›å»ºå®Œæˆ")
    
    def run_full_integration(self) -> bool:
        """è¿è¡Œå®Œæ•´é›†æˆæµç¨‹"""
        logger.info("ğŸ¯ å¼€å§‹Edge-Model-Infraå®Œæ•´é›†æˆ...")
        
        steps = [
            ("æ£€æŸ¥Edge-Model-Infraå¯ç”¨æ€§", self.check_edge_infra_availability),
            ("å‡†å¤‡ç¯å¢ƒ", self.prepare_edge_infra_environment),
            ("æ„å»ºç»„ä»¶", self.build_edge_infra_components),
            ("Dockeréƒ¨ç½²", self.deploy_with_docker),
            ("åç«¯æœåŠ¡é›†æˆ", self.integrate_with_backend_services),
            ("åˆ›å»ºå¯åŠ¨è„šæœ¬", lambda: (self.create_startup_scripts(), True)[1]),
            ("æµ‹è¯•é›†æˆ", self.test_integration)
        ]
        
        for step_name, step_func in steps:
            logger.info(f"ğŸ“‹ æ‰§è¡Œæ­¥éª¤: {step_name}")
            try:
                if not step_func():
                    logger.error(f"âŒ æ­¥éª¤å¤±è´¥: {step_name}")
                    return False
                logger.info(f"âœ… æ­¥éª¤å®Œæˆ: {step_name}")
            except Exception as e:
                logger.error(f"âŒ æ­¥éª¤å¼‚å¸¸: {step_name} - {e}")
                return False
        
        logger.info("ğŸ‰ Edge-Model-Infraé›†æˆå®Œæˆï¼")
        return True

def main():
    """ä¸»å‡½æ•°"""
    integrator = EdgeModelInfraIntegrator()
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "check":
            return integrator.check_edge_infra_availability()
        elif command == "build":
            return integrator.build_edge_infra_components()
        elif command == "deploy":
            return integrator.deploy_with_docker()
        elif command == "test":
            return integrator.test_integration()
        elif command == "full":
            return integrator.run_full_integration()
        else:
            print("ç”¨æ³•: python edge_model_infra_integration.py [check|build|deploy|test|full]")
            return False
    else:
        # é»˜è®¤è¿è¡Œå®Œæ•´é›†æˆ
        return integrator.run_full_integration()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
